{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNL+5X4DDnZbUmYGSPv/q80",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Harsh152003/Reinforcement_Learning/blob/main/Exp_7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "\n",
        "env = gym.make(\"FrozenLake-v1\")\n",
        "\n",
        "n_state = env.observation_space.n\n",
        "print(\"N states (4x4):\", n_state)\n",
        "n_action = env.action_space.n\n",
        "print(\"M actions (U, D, L, R):\", n_action)\n",
        "\n",
        "env.reset()\n",
        "print(\"\\nFrozenLake-v0 Env\")\n",
        "env.render()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mhm-3MouFP3N",
        "outputId": "83024622-eb13-4b7b-903a-800f6dc0f081"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:49: DeprecationWarning: \u001b[33mWARN: You are calling render method, but you didn't specified the argument render_mode at environment initialization. To maintain backward compatibility, the environment will render in human mode.\n",
            "If you want to render in human mode, initialize the environment in this way: gym.make('EnvName', render_mode='human') and don't call the render method.\n",
            "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
            "  deprecation(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "N states (4x4): 16\n",
            "M actions (U, D, L, R): 4\n",
            "\n",
            "FrozenLake-v0 Env\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# env model: we have knowledge about everything in the environment\n",
        "\n",
        "import pprint\n",
        "pp = pprint.PrettyPrinter(indent=4)\n",
        "pp.pprint(env.P)\n",
        "\n",
        "# {\n",
        "#     state1: {\n",
        "#         action1: [(transition_prob, next_state, reward, done)],\n",
        "#         action2: [(transition_prob, next_state, reward, done)],\n",
        "#         action3: [(transition_prob, next_state, reward, done)],\n",
        "#         action4: [(transition_prob, next_state, reward, done)],\n",
        "#     },\n",
        "#     state2: {\n",
        "#         action1: [(transition_prob, next_state, reward, done)],\n",
        "#         ...\n",
        "#     }\n",
        "#     ...\n",
        "# }"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQd3Jy08FTbe",
        "outputId": "01b39a8d-19dd-4f33-e6b7-93f54834504f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{   0: {   0: [   (0.3333333333333333, 0, 0.0, False),\n",
            "                  (0.3333333333333333, 0, 0.0, False),\n",
            "                  (0.3333333333333333, 4, 0.0, False)],\n",
            "           1: [   (0.3333333333333333, 0, 0.0, False),\n",
            "                  (0.3333333333333333, 4, 0.0, False),\n",
            "                  (0.3333333333333333, 1, 0.0, False)],\n",
            "           2: [   (0.3333333333333333, 4, 0.0, False),\n",
            "                  (0.3333333333333333, 1, 0.0, False),\n",
            "                  (0.3333333333333333, 0, 0.0, False)],\n",
            "           3: [   (0.3333333333333333, 1, 0.0, False),\n",
            "                  (0.3333333333333333, 0, 0.0, False),\n",
            "                  (0.3333333333333333, 0, 0.0, False)]},\n",
            "    1: {   0: [   (0.3333333333333333, 1, 0.0, False),\n",
            "                  (0.3333333333333333, 0, 0.0, False),\n",
            "                  (0.3333333333333333, 5, 0.0, True)],\n",
            "           1: [   (0.3333333333333333, 0, 0.0, False),\n",
            "                  (0.3333333333333333, 5, 0.0, True),\n",
            "                  (0.3333333333333333, 2, 0.0, False)],\n",
            "           2: [   (0.3333333333333333, 5, 0.0, True),\n",
            "                  (0.3333333333333333, 2, 0.0, False),\n",
            "                  (0.3333333333333333, 1, 0.0, False)],\n",
            "           3: [   (0.3333333333333333, 2, 0.0, False),\n",
            "                  (0.3333333333333333, 1, 0.0, False),\n",
            "                  (0.3333333333333333, 0, 0.0, False)]},\n",
            "    2: {   0: [   (0.3333333333333333, 2, 0.0, False),\n",
            "                  (0.3333333333333333, 1, 0.0, False),\n",
            "                  (0.3333333333333333, 6, 0.0, False)],\n",
            "           1: [   (0.3333333333333333, 1, 0.0, False),\n",
            "                  (0.3333333333333333, 6, 0.0, False),\n",
            "                  (0.3333333333333333, 3, 0.0, False)],\n",
            "           2: [   (0.3333333333333333, 6, 0.0, False),\n",
            "                  (0.3333333333333333, 3, 0.0, False),\n",
            "                  (0.3333333333333333, 2, 0.0, False)],\n",
            "           3: [   (0.3333333333333333, 3, 0.0, False),\n",
            "                  (0.3333333333333333, 2, 0.0, False),\n",
            "                  (0.3333333333333333, 1, 0.0, False)]},\n",
            "    3: {   0: [   (0.3333333333333333, 3, 0.0, False),\n",
            "                  (0.3333333333333333, 2, 0.0, False),\n",
            "                  (0.3333333333333333, 7, 0.0, True)],\n",
            "           1: [   (0.3333333333333333, 2, 0.0, False),\n",
            "                  (0.3333333333333333, 7, 0.0, True),\n",
            "                  (0.3333333333333333, 3, 0.0, False)],\n",
            "           2: [   (0.3333333333333333, 7, 0.0, True),\n",
            "                  (0.3333333333333333, 3, 0.0, False),\n",
            "                  (0.3333333333333333, 3, 0.0, False)],\n",
            "           3: [   (0.3333333333333333, 3, 0.0, False),\n",
            "                  (0.3333333333333333, 3, 0.0, False),\n",
            "                  (0.3333333333333333, 2, 0.0, False)]},\n",
            "    4: {   0: [   (0.3333333333333333, 0, 0.0, False),\n",
            "                  (0.3333333333333333, 4, 0.0, False),\n",
            "                  (0.3333333333333333, 8, 0.0, False)],\n",
            "           1: [   (0.3333333333333333, 4, 0.0, False),\n",
            "                  (0.3333333333333333, 8, 0.0, False),\n",
            "                  (0.3333333333333333, 5, 0.0, True)],\n",
            "           2: [   (0.3333333333333333, 8, 0.0, False),\n",
            "                  (0.3333333333333333, 5, 0.0, True),\n",
            "                  (0.3333333333333333, 0, 0.0, False)],\n",
            "           3: [   (0.3333333333333333, 5, 0.0, True),\n",
            "                  (0.3333333333333333, 0, 0.0, False),\n",
            "                  (0.3333333333333333, 4, 0.0, False)]},\n",
            "    5: {   0: [(1.0, 5, 0, True)],\n",
            "           1: [(1.0, 5, 0, True)],\n",
            "           2: [(1.0, 5, 0, True)],\n",
            "           3: [(1.0, 5, 0, True)]},\n",
            "    6: {   0: [   (0.3333333333333333, 2, 0.0, False),\n",
            "                  (0.3333333333333333, 5, 0.0, True),\n",
            "                  (0.3333333333333333, 10, 0.0, False)],\n",
            "           1: [   (0.3333333333333333, 5, 0.0, True),\n",
            "                  (0.3333333333333333, 10, 0.0, False),\n",
            "                  (0.3333333333333333, 7, 0.0, True)],\n",
            "           2: [   (0.3333333333333333, 10, 0.0, False),\n",
            "                  (0.3333333333333333, 7, 0.0, True),\n",
            "                  (0.3333333333333333, 2, 0.0, False)],\n",
            "           3: [   (0.3333333333333333, 7, 0.0, True),\n",
            "                  (0.3333333333333333, 2, 0.0, False),\n",
            "                  (0.3333333333333333, 5, 0.0, True)]},\n",
            "    7: {   0: [(1.0, 7, 0, True)],\n",
            "           1: [(1.0, 7, 0, True)],\n",
            "           2: [(1.0, 7, 0, True)],\n",
            "           3: [(1.0, 7, 0, True)]},\n",
            "    8: {   0: [   (0.3333333333333333, 4, 0.0, False),\n",
            "                  (0.3333333333333333, 8, 0.0, False),\n",
            "                  (0.3333333333333333, 12, 0.0, True)],\n",
            "           1: [   (0.3333333333333333, 8, 0.0, False),\n",
            "                  (0.3333333333333333, 12, 0.0, True),\n",
            "                  (0.3333333333333333, 9, 0.0, False)],\n",
            "           2: [   (0.3333333333333333, 12, 0.0, True),\n",
            "                  (0.3333333333333333, 9, 0.0, False),\n",
            "                  (0.3333333333333333, 4, 0.0, False)],\n",
            "           3: [   (0.3333333333333333, 9, 0.0, False),\n",
            "                  (0.3333333333333333, 4, 0.0, False),\n",
            "                  (0.3333333333333333, 8, 0.0, False)]},\n",
            "    9: {   0: [   (0.3333333333333333, 5, 0.0, True),\n",
            "                  (0.3333333333333333, 8, 0.0, False),\n",
            "                  (0.3333333333333333, 13, 0.0, False)],\n",
            "           1: [   (0.3333333333333333, 8, 0.0, False),\n",
            "                  (0.3333333333333333, 13, 0.0, False),\n",
            "                  (0.3333333333333333, 10, 0.0, False)],\n",
            "           2: [   (0.3333333333333333, 13, 0.0, False),\n",
            "                  (0.3333333333333333, 10, 0.0, False),\n",
            "                  (0.3333333333333333, 5, 0.0, True)],\n",
            "           3: [   (0.3333333333333333, 10, 0.0, False),\n",
            "                  (0.3333333333333333, 5, 0.0, True),\n",
            "                  (0.3333333333333333, 8, 0.0, False)]},\n",
            "    10: {   0: [   (0.3333333333333333, 6, 0.0, False),\n",
            "                   (0.3333333333333333, 9, 0.0, False),\n",
            "                   (0.3333333333333333, 14, 0.0, False)],\n",
            "            1: [   (0.3333333333333333, 9, 0.0, False),\n",
            "                   (0.3333333333333333, 14, 0.0, False),\n",
            "                   (0.3333333333333333, 11, 0.0, True)],\n",
            "            2: [   (0.3333333333333333, 14, 0.0, False),\n",
            "                   (0.3333333333333333, 11, 0.0, True),\n",
            "                   (0.3333333333333333, 6, 0.0, False)],\n",
            "            3: [   (0.3333333333333333, 11, 0.0, True),\n",
            "                   (0.3333333333333333, 6, 0.0, False),\n",
            "                   (0.3333333333333333, 9, 0.0, False)]},\n",
            "    11: {   0: [(1.0, 11, 0, True)],\n",
            "            1: [(1.0, 11, 0, True)],\n",
            "            2: [(1.0, 11, 0, True)],\n",
            "            3: [(1.0, 11, 0, True)]},\n",
            "    12: {   0: [(1.0, 12, 0, True)],\n",
            "            1: [(1.0, 12, 0, True)],\n",
            "            2: [(1.0, 12, 0, True)],\n",
            "            3: [(1.0, 12, 0, True)]},\n",
            "    13: {   0: [   (0.3333333333333333, 9, 0.0, False),\n",
            "                   (0.3333333333333333, 12, 0.0, True),\n",
            "                   (0.3333333333333333, 13, 0.0, False)],\n",
            "            1: [   (0.3333333333333333, 12, 0.0, True),\n",
            "                   (0.3333333333333333, 13, 0.0, False),\n",
            "                   (0.3333333333333333, 14, 0.0, False)],\n",
            "            2: [   (0.3333333333333333, 13, 0.0, False),\n",
            "                   (0.3333333333333333, 14, 0.0, False),\n",
            "                   (0.3333333333333333, 9, 0.0, False)],\n",
            "            3: [   (0.3333333333333333, 14, 0.0, False),\n",
            "                   (0.3333333333333333, 9, 0.0, False),\n",
            "                   (0.3333333333333333, 12, 0.0, True)]},\n",
            "    14: {   0: [   (0.3333333333333333, 10, 0.0, False),\n",
            "                   (0.3333333333333333, 13, 0.0, False),\n",
            "                   (0.3333333333333333, 14, 0.0, False)],\n",
            "            1: [   (0.3333333333333333, 13, 0.0, False),\n",
            "                   (0.3333333333333333, 14, 0.0, False),\n",
            "                   (0.3333333333333333, 15, 1.0, True)],\n",
            "            2: [   (0.3333333333333333, 14, 0.0, False),\n",
            "                   (0.3333333333333333, 15, 1.0, True),\n",
            "                   (0.3333333333333333, 10, 0.0, False)],\n",
            "            3: [   (0.3333333333333333, 15, 1.0, True),\n",
            "                   (0.3333333333333333, 10, 0.0, False),\n",
            "                   (0.3333333333333333, 13, 0.0, False)]},\n",
            "    15: {   0: [(1.0, 15, 0, True)],\n",
            "            1: [(1.0, 15, 0, True)],\n",
            "            2: [(1.0, 15, 0, True)],\n",
            "            3: [(1.0, 15, 0, True)]}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import gym\n",
        "\n",
        "def policy_evaluation(env, policy, gamma, theta, state_values):\n",
        "    \"\"\"\n",
        "    policy_evaluation: \t\testimate state values based on the policy\n",
        "\n",
        "    @param env:       \t\tOpenAI Gym environment\n",
        "    @param policy:    \t\tpolicy matrix containing actions and their probability in each state\n",
        "    @param gamma:     \t\tdiscount factor\n",
        "    @param theta: \t\t\tevaluation will stop once values for all states are less than theta\n",
        "    @param state_values: \tinitial state values\n",
        "\n",
        "    @return:         \t\tnew state values of the given policy\n",
        "    \"\"\"\n",
        "    delta = theta*2\n",
        "    state_len = env.observation_space.n  # Use observation_space.n for the number of states\n",
        "    action_len = env.action_space.n  # Use action_space.n for the number of actions\n",
        "\n",
        "    while (delta > theta):\n",
        "        delta = 0\n",
        "        # for all state\n",
        "        for s in range(state_len):\n",
        "            # we will get new state value\n",
        "            new_s = 0\n",
        "            # for all actions\n",
        "            for a in range(action_len):\n",
        "                # get the current transitions list (U,D,L,R)\n",
        "                transitions_list = env.P[s][a]\n",
        "                # for all transitions from current state\n",
        "                for i in transitions_list:\n",
        "                    transition_prob, next_state, reward, done = i\n",
        "                    new_s += policy[s, a] * transition_prob * (reward + gamma * state_values[next_state])\n",
        "\n",
        "            delta = max(delta, np.abs(new_s - state_values[s]))\n",
        "            state_values[s] = new_s\n",
        "    return state_values\n",
        "\n",
        "# Create the FrozenLake environment\n",
        "env = gym.make('FrozenLake-v1')\n",
        "\n",
        "# Discount factor gamma\n",
        "gamma = 0.99\n",
        "# Initial policy: agents can take actions at equal probability\n",
        "policy = np.ones((env.observation_space.n, env.action_space.n)) / env.action_space.n\n",
        "# Initial state values\n",
        "state_values = np.zeros(env.observation_space.n)\n",
        "theta = 0.0001\n",
        "\n",
        "print(\"****** Initial policy ******\")\n",
        "print(policy)\n",
        "print(\"****** Gamma (discount factor) ******\")\n",
        "print(gamma)\n",
        "print(\"****** Theta ******\")\n",
        "print(theta)\n",
        "state_values = policy_evaluation(env, policy, gamma, theta, state_values)\n",
        "print(\"****** Best state values ******\")\n",
        "print(np.round(state_values.reshape(4, 4), 3))\n",
        "print(\"NOTICE: state values are higher as you get closer to the goal.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_n3ais57FrmX",
        "outputId": "c0f87954-8394-4890-fbeb-cfe075656435"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "****** Initial policy ******\n",
            "[[0.25 0.25 0.25 0.25]\n",
            " [0.25 0.25 0.25 0.25]\n",
            " [0.25 0.25 0.25 0.25]\n",
            " [0.25 0.25 0.25 0.25]\n",
            " [0.25 0.25 0.25 0.25]\n",
            " [0.25 0.25 0.25 0.25]\n",
            " [0.25 0.25 0.25 0.25]\n",
            " [0.25 0.25 0.25 0.25]\n",
            " [0.25 0.25 0.25 0.25]\n",
            " [0.25 0.25 0.25 0.25]\n",
            " [0.25 0.25 0.25 0.25]\n",
            " [0.25 0.25 0.25 0.25]\n",
            " [0.25 0.25 0.25 0.25]\n",
            " [0.25 0.25 0.25 0.25]\n",
            " [0.25 0.25 0.25 0.25]\n",
            " [0.25 0.25 0.25 0.25]]\n",
            "****** Gamma (discount factor) ******\n",
            "0.99\n",
            "****** Theta ******\n",
            "0.0001\n",
            "****** Best state values ******\n",
            "[[0.012 0.01  0.019 0.009]\n",
            " [0.015 0.    0.039 0.   ]\n",
            " [0.033 0.084 0.138 0.   ]\n",
            " [0.    0.17  0.434 0.   ]]\n",
            "NOTICE: state values are higher as you get closer to the goal.\n"
          ]
        }
      ]
    }
  ]
}